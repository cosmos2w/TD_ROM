
# Notes ________________________________________
# ...
#_______________________________________________

case_index        : 0      
Stage             : 0
# 0: Only sparse reconstruction 
# 1: Only temporal propagation 
# -1: Train both together
Repeat_id         : 0 

# data ----------------------------------------------------
data_h5           : 2D_CollinearPlateFlow/Dataset/processed/Data2PlatesGap1Re40.h5

Spatial_Dim       : 2          # Spatial dimension: 1, 2 or 3
delta_t           : 0.001      
U_dim             : 1          # Dummy in this case

N_window          : 2
num_time_sample   : 4          # N_ts, for encoder to generate latent trajectory
num_space_sample  : 64         # N_xs, spatial points randomly sampled
multi_factor      : 1.0

num_workers       : 8
train_ratio       : 0.90
batch_size        : 128
num_samples       : 1024            # Resample in one case
Full_Field_DownS  : 0.25            # Downsampling ratio for reconstruction in training

channel           : 0               # Choose between 0, 1,...-1. For channel =-1 the code load all fields
process_mode      : MeanStdStand    # Choose between MinMaxNorm, MeanStdStand, SymLogQuant and None

Use_Adaptive_Selection : False          # Enable Bayesian φ
domain_decompose       : False          # Enable adaptive domain decomposition

global_restriction     : False         # Determine if we restrict the whole reconstruction area
sample_restriction     : False         # Determine if we restrict the sampling area
Sample_Parameters:                     # Regions that we limit sampling
  x_lo              : -1.0
  x_hi              : 1.0
  y_lo              : -1.0
  y_hi              : 1.0

bandwidth_init : 0.05
top_k : 64
per_sensor_sigma : True  
overlap_ratio: 0.02
importance_scale: 0.5

# model ---------------------------------------------------
Reload_Trained    : False

F_dim             : 32
num_heads         : 16
num_layers        : 2
num_layers_propagator : 4
latent_tokens     : 32               # For cross-att in perceiver reconstructor

decoder_type      : UD_Trans         # LinTrans or DelayNODE or *CausalTrans or StdTrans or UD_Trans
reconstructor_type: Perceiver        # Perceiver or DeepONet

num_freqs         : 256
pooling           : "none"             # "mean" or "cls" or "none"
hidden_dims       : [512, 512, 512]    # for the DelayNODE

# training -----------------------------------------------
num_epochs        : 100000

learning_rate     : 3.0e-4
weight_decay      : 1.0e-6       # Weight decay for AdamW
warmup_epochs     : 50
monitor_every     : 5
patience_epochs   : 1000

CalRecVar         : True
retain_cls        : True
Supervise_Sensors : True
use_temporal      : False

Loss_Traj_Weight  : 1.0

nll_anneal_epochs : 2000
nll_weight        : 0.00001

psd_weight        : 0.10
spectrum_weight   : 0.10
spectral_blend_weight : 0.5

# sparse adaptation -----------------------------------------
bayesian_phi:
  update_in_stage1 : True           # allow updates of mlp_phi in Stage-1 (temporal roll-out)
  phi_mlp_hidden_dim: 128           # Hidden size for φ MLP
  prior_alpha: 0.5                  # Beta prior: alpha (e.g., 2.0 biases toward retaining points early)
  prior_beta: 0.5                   # Beta prior: beta (e.g., 5.0 for lower drop-off probs initially)
  mc_samples_elbo: 5
  ema_alpha: 0.25                   # EMA decay for aggregating residuals (0.1 = slow adaptation)

  vi_entropy_weight: 0.010
  var_weight       : 0.10
  lambda_kl: 0.1                     # Weight for the kl loss to pull towards prior
  lambda_elbo: 0.001                 # Weight for the (negative) ELBO term in the main loss (integrates VI into single objective)

  anneal_epochs: 100                # Epochs to anneal threshold from low (retain ~1024) to high
  min_retain: 64                    # Minimum points to retain (fallback if too aggressive)
  max_retain: 64                    # Maximum points early on (warm-up)

  viz_every: 1000                    # Visualize φ every N epochs
  viz_grid_shape: [300, 88]          # 2D grid shape for φ
  viz_save_dir: Save_report_files/phi_viz           # Directory for φ PNG saves

# folders -------------------------------------------------
save_loss_dir     : Save_loss_files/collinear_flow_Re40/train_test_loss_TD-ROM
save_net_dir      : Output_Net/collinear_flow_Re40/Net_TD-ROM
save_recon_dir    : Save_reconstruction_files/collinear_flow_Re40/Results_TDROM